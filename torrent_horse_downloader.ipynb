{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-massive-world/torrent-and-youtube-downloader/blob/main/torrent_horse_downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6hF0emftx4h"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output as clear\n",
        "import json,os,time,tqdm,shutil\n",
        "os.chdir('/content/')\n",
        "\n",
        "try:\n",
        "  from humanfriendly import format_timespan, format_size\n",
        "  from datetime import date as datetimedate, datetime\n",
        "  import pytz\n",
        "  import yt_dlp\n",
        "except ModuleNotFoundError:\n",
        "  !pip install humanfriendly\n",
        "  !pip install yt_dlp\n",
        "  \n",
        "  from humanfriendly import format_timespan, format_size\n",
        "\n",
        "ifile = 'installed_libraries.json'\n",
        "try:\n",
        "  with open(ifile,'r') as f:\n",
        "    i_file = json.load(f)\n",
        "  \n",
        "  print('I already have the necessary libraries. ^-^\\n')\n",
        "except FileNotFoundError:\n",
        "  \n",
        "\n",
        "  print('I am installing libraries\\n')\n",
        "\n",
        "  import time\n",
        "  import os\n",
        "\n",
        "  !python -m pip install --upgrade pip setuptools wheel\n",
        "  !python -m pip install lbry-libtorrent\n",
        "  !apt install python3-libtorrent\n",
        "  clear()\n",
        "  !pip install IPython --upgrade\n",
        "  clear()\n",
        "  with open(ifile,'w') as f:\n",
        "    json.dump('1',f)\n",
        "\n",
        "  time.sleep(3)\n",
        "  os.kill(os.getpid(),9)\n",
        "\n",
        "import libtorrent as lt\n",
        "\n",
        "ses = lt.session()\n",
        "ses.listen_on(6881, 6891)\n",
        "downloads = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjBtuWajwH5m"
      },
      "outputs": [],
      "source": [
        "torpath = ''\n",
        "# show_progress()\n",
        "# shutil.rmtree('sample_data')\n",
        "!rm -rf /usr/local/lib/python2.7\n",
        "!rm -rf /swift\n",
        "!rm -rf /usr/local/cuda-10.1\n",
        "!rm -rf /usr/local/cuda-10.0\n",
        "!rm -rf /tensorflow-2.0.0\n",
        "!rm -rf /usr/local/python3.6/dist-packages/torch\n",
        "!rm -rf /opt/nvidia\n",
        "!rm -rf /usr/local/lib/python3.6/dist-packages/pystan\n",
        "!rm -rf /usr/local/lib/python3.6/dist-packages/spacy\n",
        "!rm -rf /usr/local/cuda-11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL4OpIfLN_ce"
      },
      "outputs": [],
      "source": [
        "# %reset -f\n",
        "tarpath = torpath\n",
        "params = {\"save_path\": torpath}\n",
        "separator = ' —— '\n",
        "sep = ' — '\n",
        "empty_list = ['',\"\",\" \",' ']\n",
        "def getfilesize(the_file,the_type):\n",
        "  file_size = os.path.getsize(the_file)\n",
        "  actual_file_size = format_size(file_size)\n",
        "\n",
        "  la_output = the_file.split('/')[-1]+sep+actual_file_size\n",
        "  \n",
        "  if the_type not in empty_list:\n",
        "    if the_type == 1:\n",
        "      return la_output.split(sep)[-1]\n",
        "    else:\n",
        "      return file_size\n",
        "  else:\n",
        "    print(la_output)\n",
        "\n",
        "def get_dir_size(path='.'):\n",
        "    total = 0\n",
        "    with os.scandir(path) as it:\n",
        "        for entry in it:\n",
        "            if entry.is_file():\n",
        "                total += entry.stat().st_size\n",
        "            elif entry.is_dir():\n",
        "                total += get_dir_size(entry.path)\n",
        "    \n",
        "    return total\n",
        "\n",
        "separator = ' —— '\n",
        "sep = ' — '\n",
        "empty_list = ['',\"\",\" \",' ']\n",
        "def normalize_keys(dictionary):\n",
        "  lst = list(dictionary.keys())\n",
        "  for item in lst:\n",
        "    # print(item)\n",
        "    new_key = norm(str(item))\n",
        "    dictionary[new_key]=dictionary.pop(item)\n",
        "\n",
        "  return dictionary\n",
        "\n",
        "def norm(a):\n",
        "  a = a.split()\n",
        "  \n",
        "  w = bytes('',encoding='utf-8')\n",
        "  for word in a:\n",
        "    my_unicode = word\n",
        "    my_unicode = my_unicode.strip('/')\n",
        "    my_unicode = my_unicode.replace('/','')\n",
        "    output = unicodedata.normalize('NFD', my_unicode).encode('ascii', 'ignore')\n",
        "    # display(w,output)\n",
        "    if output in [b'']:\n",
        "      w+=bytes(word+' ',encoding='utf-8')\n",
        "    else:\n",
        "      w+=output+bytes(' ',encoding='utf-8')\n",
        "\n",
        "  \n",
        "  return w.strip()\n",
        "\n",
        "def getfilesize(the_file,the_type):\n",
        "  file_size = os.path.getsize(the_file)\n",
        "  actual_file_size = format_size(file_size)\n",
        "\n",
        "  la_output = the_file.split('/')[-1]+sep+actual_file_size\n",
        "  \n",
        "  if the_type not in empty_list:\n",
        "    if the_type == 1:\n",
        "      return la_output.split(sep)[-1]\n",
        "    else:\n",
        "      return file_size\n",
        "  else:\n",
        "    print(la_output)\n",
        "def to_json(dic, name, string):\n",
        "  path = '/content/drive/MyDrive/essentials/unlimited_ssm/---archive---/jsons/'\n",
        "  a = 1\n",
        "  if string == 'write':\n",
        "    \n",
        "    if dic == {}:\n",
        "      print('Given Dictionary is empty. Check again!!')\n",
        "      return False\n",
        "    if a == 1:  \n",
        "\n",
        "      with open(path+name+'.json','w') as fp:\n",
        "        json.dump(dic,fp)\n",
        "    else:\n",
        "      print('Did not save anything.')\n",
        "      return False\n",
        "    \n",
        "    # print('saved '+name+'.json')\n",
        "    print('saved',sep,name,'('+getfilesize(path+name+'.json',1)+')')\n",
        "\n",
        "  if string == 'read':\n",
        "    with open(path+name+'.json','r') as fp:\n",
        "      data = json.load(fp)\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def timenow(part):\n",
        "  if part in empty_list:\n",
        "    return datetime.now(pytz.timezone(\"Etc/GMT-6\")).strftime('%d %B %Y, %I:%M:%S %p')\n",
        "  else:\n",
        "    return datetime.now(pytz.timezone(\"Etc/GMT-6\")).strftime('%d %B %Y')\n",
        "\n",
        "def time_difference(current,previous):\n",
        "  delta = (datetime.strptime(current,'%d %B %Y, %I:%M:%S %p') - datetime.strptime(previous,'%d %B %Y, %I:%M:%S %p'))\n",
        "  secondsPassed = delta.total_seconds()\n",
        "  print(format_timespan(secondsPassed))\n",
        "  return secondsPassed\n",
        "\n",
        "def torrent_data(magnet_link):\n",
        "\n",
        "  s = lt.add_magnet_uri(ses,magnet_link,params)\n",
        "  st = s.status()\n",
        "  i=0\n",
        "  while st.total_wanted == 0:\n",
        "    s = lt.add_magnet_uri(ses,magnet_link,params)\n",
        "    st = s.status()\n",
        "    print('Try #'+str(i+1))\n",
        "    i+=1\n",
        "    time.sleep(i)\n",
        "    if i>10:\n",
        "      break\n",
        "    \n",
        "\n",
        "  return st.name,st.total_wanted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCYgySqirDsy"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sizer():\n",
        "  k = []\n",
        "  try:\n",
        "    torrent = to_json({},'torrent_data_cache','read')\n",
        "  except Exception as e:\n",
        "    return ''\n",
        "  for i in torrent:\n",
        "    a,c = torrent[i]['name'],torrent[i]['total_size']\n",
        "    k.append(a+sep+str(c)+sep+format_size(c))\n",
        "  return k\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPdKiqyihgqT"
      },
      "outputs": [],
      "source": [
        "def adding_torrent_links():\n",
        "  k = sizer()\n",
        "  try:\n",
        "    torrent=to_json({},'torrent_data_cache','read')\n",
        "  except Exception as e:\n",
        "    torrent = {}\n",
        "  while True:\n",
        "    print('\\nENTER MAGNET LINK, OR \"E\" TO EXIT, or \"C\" to clear screen')\n",
        "    time.sleep(1)\n",
        "    magnet_link = input()\n",
        "    if magnet_link.lower() == 'e':\n",
        "      break\n",
        "    if magnet_link.lower() == 'c':\n",
        "      clear()\n",
        "      continue\n",
        "    a,c = torrent_data(magnet_link.strip())\n",
        "    print(a,sep,c,sep,format_size(c))\n",
        "    if c!=0:\n",
        "      torrent[magnet_link]={'name':a,\n",
        "                            'total_size':c}\n",
        "    \n",
        "  clear()\n",
        "  to_json(torrent,'torrent_data_cache','write')\n",
        "  j = sizer()\n",
        "  if list(set(k)^set(j)) != []:\n",
        "    print('Newly Added\\n')\n",
        "    c=0\n",
        "    for item in (list(set(k)^set(j))):\n",
        "      print(str(c+1)+'. '+item)\n",
        "      c+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXKWE58sw4e4"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# word = 'ghibli'\n",
        "\n",
        "\n",
        "def searcher(word):\n",
        "  for files in sorted(os.listdir('/content/drive/My Drive/Torrent')):\n",
        "    t=0\n",
        "    for words in word.split():\n",
        "      \n",
        "      if words in files.lower().split('.') or words in files.lower():\n",
        "        t+=1\n",
        "      # print(words,t,files)\n",
        "    if t==len(word.split()):\n",
        "      # print(files)\n",
        "      # getfilesize(torpath)\n",
        "      try:\n",
        "        # print('----------------------------------------------------')\n",
        "        print('\\n'+files+'\\n',format_size(get_dir_size(torpath+files)),sep,get_dir_size(torpath+files))\n",
        "        print('------------------------------------------------------')\n",
        "        for f in sorted(os.listdir(torpath+files)):\n",
        "          getfilesize(torpath+files+'/'+f,'')\n",
        "        print('------------------------------------------------------\\n')\n",
        "      except Exception as e:\n",
        "        getfilesize(torpath+files,'')\n",
        "\n",
        "      # shutil.rmtree(torpath+files)mi\n",
        "      t=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DBNoYYoSuDBT"
      },
      "outputs": [],
      "source": [
        "def show_progress():\n",
        "  import time\n",
        "  from IPython.display import display\n",
        "  import ipywidgets as widgets\n",
        "\n",
        "  state_str = [\n",
        "      \"queued\",\n",
        "      \"checking\",\n",
        "      \"downloading metadata\",\n",
        "      \"downloading\",\n",
        "      \"finished\",\n",
        "      \"seeding\",\n",
        "      \"allocating\",\n",
        "      \"checking fastresume\",\n",
        "  ]\n",
        "\n",
        "  layout = widgets.Layout(width=\"auto\")\n",
        "  style = {\"description_width\": \"initial\"}\n",
        "  download_bars = [\n",
        "      widgets.FloatSlider(\n",
        "          step=0.01, disabled=True, layout=layout, style=style\n",
        "      )\n",
        "      for _ in downloads\n",
        "  ]\n",
        "  display(*download_bars)\n",
        "\n",
        "  while downloads:\n",
        "      next_shift = 0\n",
        "      for index, download in enumerate(downloads[:]):\n",
        "          bar = download_bars[index + next_shift]\n",
        "          if not download.is_seed():\n",
        "              s = download.status()\n",
        "\n",
        "              bar.description = \" \".join(\n",
        "                  [\n",
        "                      download.name(),\n",
        "                      str(s.download_rate / 1000),\n",
        "                      \"kB/s\",\n",
        "                      state_str[s.state],\n",
        "                  ]\n",
        "              )\n",
        "              bar.value = s.progress * 100\n",
        "          else:\n",
        "              next_shift -= 1\n",
        "              ses.remove_torrent(download)\n",
        "              downloads.remove(download)\n",
        "              bar.close() # Seems to be not working in Colab (see https://github.com/googlecolab/colabtools/issues/726#issue-486731758)\n",
        "              download_bars.remove(bar)\n",
        "              print(download.name(), \"complete\")\n",
        "      time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm7gkC66iNbr"
      },
      "outputs": [],
      "source": [
        "def checks_what_to_download():\n",
        "  t = to_json({},'torrent_data_cache','read')\n",
        "  tarpath = '/content/drive/MyDrive/Torrent/'\n",
        "  d=[]\n",
        "  c=0\n",
        "  for item in t:\n",
        "    c+=1\n",
        "    file_or_folder = t[item]['name']\n",
        "    wanted = t[item]['total_size']\n",
        "    \n",
        "    if os.path.exists(tarpath+file_or_folder):\n",
        "      # print(c)\n",
        "      \n",
        "      continue\n",
        "  \n",
        "    try:\n",
        "      if os.path.isdir(file_or_folder):\n",
        "        try:\n",
        "          byte = get_dir_size(tarpath+file_or_folder)\n",
        "        except Exception as e:\n",
        "          byte = get_dir_size(''+file_or_folder)\n",
        "\n",
        "      else:\n",
        "        try:\n",
        "          byte = getfilesize(tarpath+file_or_folder,'1')\n",
        "        except Exception as e:\n",
        "          byte = getfilesize(''+file_or_folder,'1')\n",
        "      \n",
        "      if byte != wanted:\n",
        "        d.append(lt.add_magnet_uri(ses,item,params))\n",
        "        print('We need to resume download',file_or_folder)\n",
        "        print('Downloaded',format_size(byte),'of',format_size(wanted),'['+str(round((((wanted-byte)/wanted)*100),2))+'% remaining]')\n",
        "        # print('total:',wanted,'downloaded:',byte)\n",
        "        print('\\n')\n",
        "    except Exception as e:\n",
        "      continue\n",
        "      d.append(lt.add_magnet_uri(ses,item,params))\n",
        "      print('We need to resume download',file_or_folder)\n",
        "      # print('Downloaded',format_size(byte),'of',format_size(wanted),'['+str(round((((wanted-byte)/wanted)*100),2))+'% remaining]')\n",
        "      # # print('total:',wanted,'downloaded:',byte)\n",
        "      # print('\\n')\n",
        "\n",
        "\n",
        "  return d\n",
        "      \n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQu_bUsr2w3F"
      },
      "outputs": [],
      "source": [
        "from apiclient.discovery import build\n",
        " \n",
        "api_key = to_json({},'yt_api_key','read')\n",
        "youtube = build('youtube','v3',developerKey=api_key['mdsalimshahed'])\n",
        "\n",
        "def get_video_datadump(uploads_id):\n",
        "  # print('get_video_datadump function called')\n",
        "  next_page_token = None\n",
        "  videos = []\n",
        "  while 1:\n",
        "    playlist_response = youtube.playlistItems().list(playlistId=uploads_id,\n",
        "                                                     part='snippet',\n",
        "                                                     maxResults=50,\n",
        "                                                     pageToken=next_page_token).execute()   # 1 unit\n",
        "    \n",
        "    videos += playlist_response['items']\n",
        "    next_page_token = playlist_response.get('nextPageToken')\n",
        " \n",
        "    \n",
        "    if next_page_token is None:\n",
        "      break\n",
        "  \n",
        "  # print('\\nCollected',len(videos),'videos\\n')\n",
        "  print('Datadump collected...')\n",
        " \n",
        "  return videos\n",
        "\n",
        "def illegal_diminisher(file_name):\n",
        "  p1 ='\\/:*?\"<>|'\n",
        "  file_name = file_name.replace('/','∕')\n",
        "  file_name = file_name.replace('?','？')\n",
        "  \n",
        "  file_name = file_name.replace('|','｜')\n",
        "  file_name = file_name.translate(str.maketrans(\"\",\"\",p1)).strip()\n",
        "\n",
        "  return file_name\n",
        "\n",
        "def downloaded_ids(channelname):\n",
        "  g=[]\n",
        "  for item in os.listdir(ytpath+channelname):\n",
        "    a,b,c= item.split(sep)\n",
        "    g.append(c.split('.')[0])\n",
        "  return g\n",
        "\n",
        "def get_channel_id_from_channel_name(channel_name):\n",
        "  # ids = {}\n",
        "  ids1 = to_json({},'channel_dict','read')\n",
        "  for item in ids1:\n",
        "    if ''.join(channel_name.split()).lower() in ''.join(item.split()).lower():\n",
        "      print(item)\n",
        "      print('Found '+channel_name+' as '+item+' in dictionary')\n",
        "      return item,ids1[item]['id'],ids1[item]['upload_id']\n",
        "  else:\n",
        "    search_response = youtube.search().list(part='snippet',\n",
        "                                            type='channel',\n",
        "                                            q=channel_name\n",
        "                                            ).execute()       # 100 unit\n",
        "    i=0\n",
        "    ids = []\n",
        "    ids_name= []\n",
        "    for item in search_response['items']:\n",
        "      c_id = item['id']['channelId']\n",
        "      title = item['snippet']['channelTitle']\n",
        "      i+=1\n",
        "      ids.append(c_id)\n",
        "      ids_name.append(title)\n",
        "      print(str(i)+'. '+title+sep+c_id,'\\nhttps://www.youtube.com/channel/'+c_id+'\\n')\n",
        "\n",
        "    choice = int(input('Channel index: '))-1\n",
        "    \n",
        "\n",
        "    ids1[ids_name[choice]]={'id':ids[choice],\n",
        "                            'link':'https://www.youtube.com/channel/'+ids[choice]}\n",
        "    \n",
        "    channel_response = youtube.channels().list(id=ids[choice],\n",
        "                                             part='contentDetails').execute()      # 1 unit\n",
        "\n",
        "    uploads_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "    ids1[ids_name[choice]]['upload_id']=uploads_id\n",
        "    ids1[ids_name[choice]]['upload_playlist']='https://www.youtube.com/playlist?list='+uploads_id\n",
        "    display(ids1[ids_name[choice]])\n",
        "    to_json(ids1,'channel_dict','write')\n",
        "    \n",
        "    return ids_name[choice],ids[choice],uploads_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1aXYJcZOHhL"
      },
      "outputs": [],
      "source": [
        "def folder_getter(folder):\n",
        "  for files in sorted(os.listdir(folder)):\n",
        "    if os.path.isdir(folder+'/'+files):\n",
        "      print('\\n'+files,sep,format_size(get_dir_size(folder+'/'+files)))\n",
        "      print('------------------------------')\n",
        "      folder_getter(folder+'/'+files+'/')\n",
        "    else:\n",
        "      if os.path.splitext(files)[-1] not in not_allowed:\n",
        "        getfilesize(folder+'/'+files,'')\n",
        "  print('------------------------------\\n')\n",
        "\n",
        "\n",
        "def deep_searcher(folder):\n",
        "  torpath = '/content/drive/MyDrive/Torrent/'\n",
        "  for files in sorted(os.listdir(torpath)):\n",
        "    t=0\n",
        "    for word in folder.lower().split():\n",
        "      if word in files.lower().replace('.',' ').split():\n",
        "        t+=1\n",
        "    if t==len(folder.split()):\n",
        "      ch = files\n",
        "      print('xx----xxxxx----xx')\n",
        "      try:\n",
        "        folder_getter(torpath+files)\n",
        "        \n",
        "        print(files+sep+format_size(get_dir_size(torpath+files)),sep,get_dir_size(torpath+files))\n",
        "        print('xx----xxxxx----xx\\n')\n",
        "      except Exception as e:\n",
        "        print('\\n--------------------')\n",
        "        getfilesize(torpath+files,'')\n",
        "        print('--------------------\\n')\n",
        "\n",
        "      # print(files+sep+format_size(get_dir_size(torpath+files)),sep,get_dir_size(torpath+files))\n",
        "      # print('------------------xx----xxxxx----xx-----------------------\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DnZHsqZ5zEk"
      },
      "outputs": [],
      "source": [
        "def saver():\n",
        "  t = to_json({},'torrent_data_cache','read')\n",
        "  \n",
        "  for item in t:\n",
        "    \n",
        "    if t[item]['name'] in os.listdir('/content/drive/MyDrive/Torrent/'):\n",
        "      continue\n",
        "    else:\n",
        "      try:\n",
        "        if get_dir_size(t[item]['name']) == t[item]['total_size']:\n",
        "          k = to_json({},'torrent_data','read')\n",
        "          k[item]=t[item]\n",
        "          to_json(k,'torrent_data','write')\n",
        "          print('Moving',t[item]['name'])\n",
        "          shutil.copytree(t[item]['name'],'/content/drive/MyDrive/Torrent/'+t[item]['name'])\n",
        "          time.sleep(1)\n",
        "          shutil.rmtree(t[item]['name'])\n",
        "      except Exception as e:\n",
        "        if getfilesize(t[item]['name'],'1') == t[item]['total_size']:\n",
        "          k = to_json({},'torrent_data','read')\n",
        "          k[item]=t[item]\n",
        "          to_json(k,'torrent_data','write')\n",
        "          print('Moving',t[item]['name'])\n",
        "          shutil.copy(t[item]['name'],'/content/drive/MyDrive/Torrent/'+t[item]['name'])\n",
        "          time.sleep(1)\n",
        "          os.remove(t[item]['name'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vULIy87IAQ7"
      },
      "outputs": [],
      "source": [
        "def remove_torrent():\n",
        "  t = to_json({},'torrent_data_cache','read')\n",
        "  k = []\n",
        "  c = 0\n",
        "  toy = list(t.keys())\n",
        "  for item in toy:\n",
        "    c+=1\n",
        "    print(str(c)+'. '+t[item]['name'])\n",
        "    k.append(t[item]['name'])\n",
        "\n",
        "  choice = input('\\nRemove which one? ')\n",
        "\n",
        "  if choice not in empty_list:\n",
        "    choice = int(choice.strip())\n",
        "    r = k[choice-1]\n",
        "  else:\n",
        "    return 'Ok, bai'\n",
        "\n",
        "  for item in toy:\n",
        "    if r == t[item]['name']:\n",
        "      t.pop(item)\n",
        "      to_json(t,'torrent_data_cache','write')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B479u-zkLJ9s"
      },
      "outputs": [],
      "source": [
        "# remove_torrent()\n",
        "adding_torrent_links()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO0zq9JOuTw2"
      },
      "outputs": [],
      "source": [
        "##CTRL+F8\n",
        "loop = 1000\n",
        "for i in range(loop):\n",
        "  if i%5==0 and i!=0:\n",
        "    clear()\n",
        "    \n",
        "  print('CURRENT LOOP:',str(i+1))\n",
        "  # clear()\n",
        "  print(timenow(''))\n",
        "  downloads = checks_what_to_download() \n",
        "  \n",
        "  \n",
        "  saver()\n",
        "  if loop >1:\n",
        "    if downloads == []:\n",
        "      break\n",
        "    print('-----------------')        \n",
        "    time.sleep(120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVnZsl1jyGxx"
      },
      "outputs": [],
      "source": [
        "sec = 1\n",
        "folder = 'Avatar.The.Way.of.Water.2022.V1.YG'\n",
        "for item in range(sec):\n",
        "  try:\n",
        "    tok.append(folder+'\\n'+timenow('')+sep+format_size(get_dir_size(folder)))\n",
        "  except Exception as e:\n",
        "    tok=[]\n",
        "    tok.append(folder+'\\n'+timenow('')+sep+format_size(get_dir_size(folder)))\n",
        "  if len(tok)>5:\n",
        "    for i in tok[-5:]:\n",
        "      print(i+'\\n')\n",
        "      \n",
        "  else:\n",
        "    for i in tok:\n",
        "      print(i+'\\n')\n",
        "  if sec>1 and item < sec-1:\n",
        "    print('-------------')\n",
        "    # time.sleep(150)\n",
        "    clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyUhRNGGop48"
      },
      "outputs": [],
      "source": [
        "for item in tok:\n",
        "  print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du2TKWSk7ejm"
      },
      "outputs": [],
      "source": [
        "not_allowed = ['.png','.srt','.nfo','.txt']\n",
        "\n",
        "deep_searcher('sopranos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m-K69Nv9SlU"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "k=0\n",
        "torpath = '/content/drive/MyDrive/Torrent/'\n",
        "\n",
        "a,b = 131,131\n",
        "a,b = 0,''\n",
        "\n",
        "delete =1\n",
        "\n",
        "# delete = 8459652365 #########################################\n",
        "for item in sorted(os.listdir(torpath)):\n",
        "  if b in empty_list:\n",
        "    b = len(os.listdir(torpath))\n",
        "  if i in range(a,b+1):\n",
        "    try:\n",
        "      print(i,sep,format_size(get_dir_size(torpath+item)),sep,item)\n",
        "      k+=get_dir_size(torpath+item)\n",
        "    except NotADirectoryError:\n",
        "      print(i,sep,format_size(getfilesize(torpath+item,2)),sep,item)\n",
        "      k+=getfilesize(torpath+item,2)\n",
        "    if delete == 8459652365:\n",
        "      try:\n",
        "        print('DELETING')\n",
        "        shutil.rmtree(torpath+item)\n",
        "      except NotADirectoryError:\n",
        "        print('DELETING')\n",
        "        os.remove(torpath+item)\n",
        "  i+=1\n",
        "\n",
        "t = to_json({},'torrent_data_cache','read')\n",
        "torpath = '/content/drive/MyDrive/Torrent/'\n",
        "to_delete = []\n",
        "for item in t:\n",
        "  if t[item]['name'] not in os.listdir(torpath):\n",
        "    to_delete.append(item)\n",
        "\n",
        "for item in to_delete:\n",
        "  t.pop(item)\n",
        "to_json(t,'torrent_data_cache','write')\n",
        "\n",
        "print('TOTAL FOLDER SIZE: ',format_size(k))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('Avatar.The.Way.Of.Water.2022.HDTS.1080p.Rus.Dub.TS.2.0.mkv','/content/drive/MyDrive/Torrent/Avatar.The.Way.Of.Water.2022.HDTS.1080p.Rus.Dub.TS.2.0.mkv')"
      ],
      "metadata": {
        "id": "ZXitCdwFPNPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvxGAZlmFtX9"
      },
      "outputs": [],
      "source": [
        "###YOUTUBER\n",
        "q = input()\n",
        "\n",
        "ytpath = '/content/drive/MyDrive/YouTube/'\n",
        "if os.path.exists(ytpath) is False:\n",
        "  os.mkdir(ytpath)\n",
        "channelname,channelid, uploadid = get_channel_id_from_channel_name(q)\n",
        "videos=''\n",
        "if os.path.exists(ytpath+channelname) is False:\n",
        "  os.mkdir(ytpath+channelname)\n",
        "videos = get_video_datadump(uploadid)\n",
        "all_vids = []\n",
        "for video in videos:\n",
        "  all_vids.append(video['snippet']['resourceId']['videoId']+sep+video['snippet']['title'])\n",
        "i= 0\n",
        "index_vids = []\n",
        "for item in all_vids[::-1]:\n",
        "  i+=1\n",
        "  index = str(i)\n",
        "  id = item.split('.\\u200b ')[0].split(sep)[0].strip()\n",
        "  name = illegal_diminisher(item.split('.\\u200b ')[0].split(sep)[-1].strip())\n",
        "  # print(index+sep+name+sep+id)\n",
        "  index_vids.append(index+sep+name+sep+id)\n",
        "t = to_json({},'channel_dict','read')\n",
        "if 'video_list' in t[channelname]:\n",
        "  if len(index_vids)>len(t[channelname]['video_list']):\n",
        "    print('Adding something extra.....')\n",
        "    t[channelname]['video_list']=index_vids\n",
        "    to_json(t,'channel_dict','write')\n",
        "\n",
        "else:\n",
        "  print('Adding anew....')\n",
        "  t[channelname]['video_list']=index_vids\n",
        "  to_json(t,'channel_dict','write')\n",
        "  \n",
        "print(channelname,'has',len(t[channelname]['video_list']),'video')\n",
        "t=to_json({},'channel_dict','read')\n",
        "videos = t[channelname]['video_list']\n",
        "number_of_videos = 10\n",
        "videos[::-1][0:number_of_videos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaL0oIPhMpbq"
      },
      "outputs": [],
      "source": [
        "not_see = ['.config','drive','installed_libraries.json','.ipynb_checkpoints','sample_data']\n",
        "i=0\n",
        "download_this = [1,2,3,4,5,6,7,8,9]\n",
        "for item in videos:\n",
        "  i+=1\n",
        "  a,b,c = item.split(sep)\n",
        "  # print(item)\n",
        "  if i not in download_this:\n",
        "    # i+=1\n",
        "    print(item,'skipping')\n",
        "    continue\n",
        "  else:\n",
        "    # i+=1\n",
        "    clear()\n",
        "    \n",
        "    print('('+str(i)+'/'+str(len(videos))+')')\n",
        "    print('Downloading',item)\n",
        "    link = 'https://www.youtube.com/watch?v='+c\n",
        "    \n",
        "    !yt-dlp https://www.youtube.com/watch?v=$c$\n",
        "    \n",
        "    vid_file = ''\n",
        "    for fl in os.listdir('.'):\n",
        "      if fl not in not_see:\n",
        "        vid_file=fl\n",
        "        break\n",
        "    \n",
        "    try:\n",
        "      shutil.move(vid_file,ytpath+channelname+'/'+a+sep+b+sep+c+'.mp4')\n",
        "      time.sleep(2)\n",
        "    except FileNotFoundError:\n",
        "      continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MN6WoYd0vXr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos[::-1][0:10]"
      ],
      "metadata": {
        "id": "aC0iIS9viAku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwS7H9eitTkh"
      },
      "outputs": [],
      "source": [
        "print(ytpath,sep,format_size(get_dir_size(ytpath))+'\\n')\n",
        "\n",
        "for item in os.listdir(ytpath):\n",
        "  if get_dir_size(ytpath+item) == 0:\n",
        "    # shutil.rmtree(ytpath+item)\n",
        "    print(item,'-----------------------')\n",
        "  else:\n",
        "    print(item,sep,format_size(get_dir_size(ytpath+item)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kwDN_Bi7RJu"
      },
      "outputs": [],
      "source": [
        "# t= to_json({},'channel_dict','read')\n",
        "# t.pop('Eminem - Topic')\n",
        "# to_json(t,'channel_dict','write')\n",
        "# t['Doja Cat']"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKUjGQPqDYI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset -f\n",
        "from urllib.parse import quote\n",
        "from IPython.display import clear_output as clear\n",
        "from imdb import Cinemagoer\n",
        "import os, shutil\n",
        "ia  = Cinemagoer()\n",
        "replacer_punct = '/\\:*?\"<>|'\n",
        "sep = ' — '\n",
        "year = ''\n",
        "network = ''\n",
        "# path = 'C:/Users/SHAJID/Videos/'\n",
        "path = '/content/'\n",
        "#search_movie = input('Search term for movie: ')\n",
        "#movie_link = 'https://www.imdb.com/find?q='+quote(search_movie)\n",
        "#print('\\n'+movie_link)\n",
        "movie_link = input('\\nThe IMDb link: ')\n",
        "movie_imdb_id = int(movie_link.split('/tt')[-1].split('/')[0])\n",
        "movie_data = ia.get_movie(movie_imdb_id)\n",
        "try:\n",
        "  ia.update(movie_data,'episodes')\n",
        "  year = 0\n",
        "  network = 1\n",
        "  episode_list = []\n",
        "  for s in range(movie_data['seasons']):\n",
        "    for e in range(len(movie_data['episodes'][s+1])):\n",
        "      episode_name = 'Season '+str(s+1)+' Episode '+str(e+1)+sep+movie_data['episodes'][s+1][e+1].data['title']\n",
        "      eoisode_name = episode_name.replace(\":\",\",\")\n",
        "      episode_name = episode_name.translate(str.maketrans(\"\",\"\",replacer_punct))\n",
        "      episode_list.append(episode_name)\n",
        "      # print(episode_name)\n",
        "    # print('\\n')\n",
        "except Exception as e:\n",
        "  year = 1\n",
        "  clear()\n",
        "  \n",
        "folder_name = movie_data['title']\n",
        "pure_folder_name = movie_data['title']\n",
        "if year == 1:\n",
        "  folder_name += ' ('+str(movie_data['year'])+')'\n",
        "if network == 1:\n",
        "  folder_name += ' ('+movie_data['distributors'][0].data['name']+')'\n",
        "clear()\n",
        "folder_name = folder_name.replace(\":\",\",\")\n",
        "folder_name = folder_name.translate(str.maketrans(\"\",\"\",replacer_punct))\n",
        "pure_folder_name = pure_folder_name.replace(\":\",\",\")\n",
        "pure_folder_name = pure_folder_name.translate(str.maketrans(\"\",\"\",replacer_punct))\n",
        "if os.path.exists(path+folder_name) is False:\n",
        "  os.mkdir(path+folder_name)\n",
        "try:\n",
        "  for item in episode_list:\n",
        "    tree1 = item.split(sep)[0]\n",
        "    if os.path.exists(path+folder_name+'/'+tree1) is False:\n",
        "      os.mkdir(path+folder_name+'/'+tree1)\n",
        "      print(path+folder_name+'/'+tree1)\n",
        "\n",
        "  for item in episode_list:\n",
        "    fol,eps = item.split(sep)\n",
        "    curr_fol = path+folder_name+'/'+fol+'/'\n",
        "    if os.listdir(curr_fol) != []:\n",
        "      for files in os.listdir(curr_fol):\n",
        "        os.rename(curr_fol+files,curr_fol+eps+os.path.splitext(files)[-1])\n",
        "except Exception as e:\n",
        "  for files in os.listdir(path+folder_name):\n",
        "    if os.listdir(path+folder_name) != []:\n",
        "      for item in os.listdir(path+folder_name):\n",
        "        os.rename(path+folder_name+'/'+files,path+folder_name+'/'+pure_folder_name+os.path.splitext(files)[-1])\n",
        "\n"
      ],
      "metadata": {
        "id": "BlBu4NnqDVEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = ia.get_movie('3581920')\n",
        "m"
      ],
      "metadata": {
        "id": "NuqYIF-zDgB5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1QFZ12H9j9XPoazhEE2NG1utN9AxCM1vW",
      "authorship_tag": "ABX9TyP33pF1VwvHad0nw0OF+VLk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}